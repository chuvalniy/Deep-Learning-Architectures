{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\n\nfrom torch.nn import functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-13T14:50:47.172770Z","iopub.execute_input":"2023-09-13T14:50:47.173271Z","iopub.status.idle":"2023-09-13T14:50:47.180404Z","shell.execute_reply.started":"2023-09-13T14:50:47.173236Z","shell.execute_reply":"2023-09-13T14:50:47.178673Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads, p_dropout=0.1):\n        super(MultiHeadAttention, self).__init__()\n        \n        self.query = nn.Linear(d_model, d_model)\n        self.key = nn.Linear(d_model, d_model)\n        self.value = nn.Linear(d_model, d_model)\n        \n        self.proj = nn.Linear(d_model, d_model)\n        \n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.heads_dim = d_model // num_heads\n        \n        self.dropout = nn.Dropout(p_dropout)\n        \n    def forward(self, q, k, v, mask=None):\n        \n        _, s_seq_len, _ = q.shape\n        batch_size, t_seq_len, d_model = k.shape\n        \n        query = self.query(q)\n        key = self.key(k)\n        value = self.value(v)\n        \n        query = query.reshape((batch_size, s_seq_len, self.num_heads, self.heads_dim)).transpose(1, 2)\n        key = key.reshape((batch_size, t_seq_len, self.num_heads, self.heads_dim)).transpose(1, 2)\n        value = value.reshape((batch_size, t_seq_len, self.num_heads, self.heads_dim)).transpose(1, 2)\n        \n        scaled_dot_product = (query @ key.transpose(2, 3)) / np.sqrt(self.heads_dim)\n        \n        if mask is not None:\n            scaled_dot_product = scaled_dot_product.masked_fill(mask == 0, float('-inf'))\n            \n        attention = (F.softmax(scaled_dot_product, dim=-1) @ value).transpose(1, 2).reshape(batch_size, s_seq_len, d_model)\n        \n        output = self.proj(attention)\n        \n        return self.dropout(output)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:53:37.072836Z","iopub.execute_input":"2023-09-13T14:53:37.073438Z","iopub.status.idle":"2023-09-13T14:53:37.091125Z","shell.execute_reply.started":"2023-09-13T14:53:37.073394Z","shell.execute_reply":"2023-09-13T14:53:37.089712Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model, p_dropout=0.1, max_length=5000):\n        super(PositionalEncoding, self).__init__()\n        \n        self.pe = torch.zeros(1, max_length, d_model)\n        self.dropout = nn.Dropout(p_dropout)\n        \n        for pos in range(max_length):\n            for i in range(0, d_model, 2):\n                self.pe[:, pos, i] = np.sin(i / 10_000**(i/d_model))\n                self.pe[:, pos, i+1] = np.cos(i / 10_000**(i/d_model))\n        \n    def forward(self, x):\n        batch_size, sequence_length, d_model = x.shape\n        \n        return self.dropout(x + self.pe[:, :sequence_length, :])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:53:37.218819Z","iopub.execute_input":"2023-09-13T14:53:37.219585Z","iopub.status.idle":"2023-09-13T14:53:37.229073Z","shell.execute_reply.started":"2023-09-13T14:53:37.219539Z","shell.execute_reply":"2023-09-13T14:53:37.227824Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(nn.Module):\n    def __init__(self, d_model, num_heads, p_dropout=0.1):\n        super(TransformerEncoder, self).__init__()\n        \n        self.pe = PositionalEncoding(d_model, p_dropout)\n        self.mha = MultiHeadAttention(d_model, num_heads, p_dropout)\n        self.ln_mha = nn.LayerNorm(d_model)\n        \n        self.ff1 = nn.Linear(d_model, d_model * 4)\n        self.relu = nn.ReLU()\n        self.ff2 = nn.Linear(d_model * 4, d_model)\n        self.ln_ff = nn.LayerNorm(d_model)\n        \n    def forward(self, x):\n        x = self.pe(x)\n        out = self.mha(x, x, x)\n        x = out + x\n        x = self.ln_mha(x)\n        \n        out = self.ff1(x)\n        out = self.relu(out)\n        out = self.ff2(out)\n        x = out + x \n        x = self.ln_ff(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:53:37.340949Z","iopub.execute_input":"2023-09-13T14:53:37.341799Z","iopub.status.idle":"2023-09-13T14:53:37.351453Z","shell.execute_reply.started":"2023-09-13T14:53:37.341758Z","shell.execute_reply":"2023-09-13T14:53:37.350396Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"class TransformerDecoder(nn.Module):\n    def __init__(self, d_model, nun_heads, p_dropout=0.1):\n        super(TransformerDecoder, self).__init__()\n        \n        self.pe = PositionalEncoding(d_model, p_dropout)\n        self.mmha = MultiHeadAttention(d_model, nun_heads, p_dropout)\n        self.ln_mmha = nn.LayerNorm(d_model)\n        \n        self.mha = MultiHeadAttention(d_model, nun_heads, p_dropout)\n        self.ln_mha = nn.LayerNorm(d_model)\n                \n        self.ff1 = nn.Linear(d_model, d_model * 4)\n        self.relu = nn.ReLU()\n        self.ff2 = nn.Linear(d_model * 4, d_model)\n        self.ln_ff = nn.LayerNorm(d_model)\n        \n    def forward(self, x, y):\n        _, t_seq_len, _ = y.shape\n        \n        y = self.pe(y)\n        \n        mask = torch.tril(torch.ones(size=(t_seq_len, t_seq_len)))\n        out = self.mmha(y, y, y, mask)\n        y = out = y\n        y = self.ln_mmha(y)\n        \n        out = self.mha(y, x, x)\n        y = out + y\n        y = self.ln_mha(y)\n        \n        out = self.ff1(y)\n        out = self.relu(out)\n        out = self.ff2(out)\n        y = out + y\n        y = self.ln_ff(y)\n        \n        return y","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:53:37.472938Z","iopub.execute_input":"2023-09-13T14:53:37.473674Z","iopub.status.idle":"2023-09-13T14:53:37.486022Z","shell.execute_reply.started":"2023-09-13T14:53:37.473640Z","shell.execute_reply":"2023-09-13T14:53:37.484653Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, d_model, vocab_size, num_heads, p_dropout=0.1):\n        super(Transformer, self).__init__()\n        \n        self.enc_embedding = nn.Embedding(vocab_size, d_model)\n        self.dec_embedding = nn.Embedding(vocab_size, d_model)\n        \n        self.encoder = TransformerEncoder(d_model, num_heads)\n        self.decoder = TransformerDecoder(d_model, num_heads)\n        \n        self.proj = nn.Linear(d_model, vocab_size)\n        \n        \n    def forward(self, src, tgt):\n        src_emb = self.enc_embedding(src)\n        src_out = self.encoder(src_emb)\n        \n        tgt_emb = self.dec_embedding(tgt)\n        out = self.decoder(src_out, tgt_emb)\n        \n        out = self.proj(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:53:37.584871Z","iopub.execute_input":"2023-09-13T14:53:37.585623Z","iopub.status.idle":"2023-09-13T14:53:37.594120Z","shell.execute_reply.started":"2023-09-13T14:53:37.585578Z","shell.execute_reply":"2023-09-13T14:53:37.592789Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"d_model = 16\nvocab_size = 10000\nnum_heads = 2\nseq_length = 10\nbatch_size = 8\n\n# Transformer instance\nmodel = Transformer(d_model, vocab_size, num_heads)\n\n# Генерируем случайные значения для X и y\nX = torch.randint(0, vocab_size, (batch_size, seq_length))\ny = torch.randint(0, vocab_size, (batch_size, seq_length))\n\n# Проходим через модель\noutput = model(X, y)\n\nprint(output.shape) ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:53:37.719852Z","iopub.execute_input":"2023-09-13T14:53:37.720664Z","iopub.status.idle":"2023-09-13T14:53:40.144406Z","shell.execute_reply.started":"2023-09-13T14:53:37.720628Z","shell.execute_reply":"2023-09-13T14:53:40.143157Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"torch.Size([8, 10, 10000])\n","output_type":"stream"}]}]}