{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-27T04:30:56.704116Z","iopub.execute_input":"2023-07-27T04:30:56.704769Z","iopub.status.idle":"2023-07-27T04:31:01.001842Z","shell.execute_reply.started":"2023-07-27T04:30:56.704715Z","shell.execute_reply":"2023-07-27T04:31:01.000867Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class VGG(nn.Module):\n    _config = {\n        \"VGG11_A\": (64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'),\n        \"VGG13_B\": (64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'),\n        \"VGG16_D\": (64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'),\n        \"VGG19_E\": (64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512,'M'),\n    }\n        \n    def __init__(self, in_channels=3, num_classes=1000, config_name='VGG16'):\n        super(VGG, self).__init__()\n        \n        self.in_channels = in_channels\n        self.num_classes = num_classes\n        \n        self.config = VGG._config[config_name]\n            \n        self.conv_layers = self._create_conv_layers()\n        self.flatten = nn.Flatten()\n        self.fc_layers = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.Dropout(p=0.5),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, 4096),\n            nn.Dropout(p=0.5),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, self.num_classes)\n        )\n    \n        \n    def forward(self, X):\n        X = self.conv_layers(X)\n        X = self.flatten(X)\n        X = self.fc_layers(X)\n        \n        return X\n    \n    def _create_conv_layers(self):\n        layers = []\n        in_channels = self.in_channels\n        \n        for config_param in self.config:\n            if isinstance(config_param, int):\n                layers.extend([\n                    nn.Conv2d(in_channels, config_param, kernel_size=3, padding=1, stride=1),\n                    nn.BatchNorm2d(config_param),\n                    nn.ReLU()\n                ])\n                \n                in_channels = config_param\n            else:\n                layers.append(\n                    nn.MaxPool2d(kernel_size=2, stride=2)\n                )\n                \n            \n        return nn.Sequential(*layers)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T06:08:44.096161Z","iopub.execute_input":"2023-07-27T06:08:44.096631Z","iopub.status.idle":"2023-07-27T06:08:44.110027Z","shell.execute_reply.started":"2023-07-27T06:08:44.096595Z","shell.execute_reply":"2023-07-27T06:08:44.108564Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = VGG(config_name='VGG19').to(device)\ndata = torch.randn(1, 3, 224, 224).to(device)\nprint(model(data).shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T06:08:44.556772Z","iopub.execute_input":"2023-07-27T06:08:44.557196Z","iopub.status.idle":"2023-07-27T06:08:46.594621Z","shell.execute_reply.started":"2023-07-27T06:08:44.557161Z","shell.execute_reply":"2023-07-27T06:08:46.593077Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"torch.Size([1, 1000])\n","output_type":"stream"}]},{"cell_type":"code","source":"print([256] * 4)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T06:12:09.773756Z","iopub.execute_input":"2023-07-27T06:12:09.774172Z","iopub.status.idle":"2023-07-27T06:12:09.781647Z","shell.execute_reply.started":"2023-07-27T06:12:09.774141Z","shell.execute_reply":"2023-07-27T06:12:09.780213Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"[256, 256, 256, 256]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}